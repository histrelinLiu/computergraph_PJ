# 音频可视化 
## 学号: 15307130083, 姓名: 刘瑞林
# 算法与程序使用说明:
## 开发环境: 
    win10 + python(32位) + pyOpenGL(32位)
    其他python包: pygame soundfile numpy time
## 算法流程:
    1. 使用soundfile读取音频文件
    2. 时域转频域, 使用了大三下学期的数字信号处理课程PJ的代码.
        1. 预加重0.97
        2. 帧长0.025秒, 步长0.0125秒
        3. 取汉明窗, 计算1200点的FFT
        4. 取模的平方,归一化
    3. OpenGL初始化窗口
    4. 绘制说明:
        1. 均适用浮点数绘制图形
        2. 使用glBegin(), glVertex2f(), glEnd() 进行绘制
    5. 上半部分绘制频域信号
        1. 绘制FFT算出来的前600个点, 每一个点绘制一个长条矩形
        2. 每一条的宽度为(deltax = 0.01) / 8 = 0.00125
        3. 颜色使用RGB(156/255, 33/255, 137/255)
    6. 小半部分绘制时域信号
        1. 选取连续的640*138/32=2760个点, 即2760/44100 = 0.0625秒的信号
        2. 一共绘制均匀分布的640个点
        3. 颜色与频域信号相同
    7. 视觉与听觉同步算法
        1. 在开始绘制时, 使用pygame播放音乐, 并记录开始时间
        2. 计算 (当前时间 - 开始时间) / 步长(0.0125s), 绘制这一帧的信号.
## 使用说明
    运行music.py默认播放AllFallsDown.flac, 并绘制可视化信号, 计算频域信号需要花费一点时间.
    需要播放其他音频,请修改music.py :line 11 "AudioFile"